{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程 feature engineering\n",
    "- feature extraction: 从文字、图像、声音等非结构化数据中提取新信息作为特征。如从淘宝商品的名称中提取产品类型等\n",
    "- feature creation： 把现有特征组合或相互计算，得到新的特征。\n",
    "- feature selection： 选择有意义的特征，选出对模型有帮助的特征，避免将所有特征都导入\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "选择有意义的特征，选出对模型有帮助的特征，避免将所有特征都导入\n",
    "\n",
    "无法依赖对业务的理解来选择特征：过滤法、嵌入法、包装法and降维算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.feature_selection import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'./digit-recognizer/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter过滤法\n",
    "通常用作预处理步骤，独立于任何机器学习算法，主要根据各种统计检验的指标来选择特征\n",
    "\n",
    "- 方差过滤：，可以删除。\n",
    "特征和标签之间的关联性\n",
    "- 卡方过滤：\n",
    "- F检验和互信息法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方差过滤\n",
    "特征方差较小，表明样本在这个特征上差别不大，甚至相同，这样的特征无意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 708)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# 该类的参数为threshold\n",
    "selector = VarianceThreshold() # 实例化，默认参数为0\n",
    "x_var0 = selector.fit_transform(X)  # 获取删除不合格特征之后的新特征矩阵，narray\n",
    "x_var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352.286703180131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进一步减少特征， 如减少到一半， 采取中位数\n",
    "# - 如何取到中位数\n",
    "X.var() # Series对象\n",
    "np.median(X.var().values)\n",
    "# 考虑前50或前100个特征\n",
    "# -将X.var()排序后取出相应值然后放入threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 392)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsvar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类的特征，其取值为伯努利随机变量，方差为：\n",
    "$$Var[X]=p(1-p)$$\n",
    "其中X为特征矩阵，p是二分类特征中的一类在这个特征中的概率。\n",
    "\n",
    "某种分类占到80%以上删除特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 685)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bvar = VarianceThreshold(0.8*(1-0.8)).fit_transform(X)\n",
    "x_bvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例：方差过滤对模型的影响\n",
    "# Time Warning： 4h\n",
    "# kNN vs RFC在不同方差过滤效果下的对比\n",
    "# kNN必须遍历每个特征和每个样本：故其不适用于大量样本的数据\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x = data.iloc[:,1:] # 过滤前的特征矩阵\n",
    "y = data.iloc[:,0]\n",
    "\n",
    "x_fsvar = VarianceThreshold(np.median(x.var().values)).fit_transform(x)  # 方差过滤后1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fsvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% timeit #每个cell运行的时间\n",
    "cross_val_score(KNN(),x,y,cv=5).mean()\n",
    "# 0.9656 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% timeit \n",
    "cross_val_score(KNN(),x_fsvar,y,cv=5).mean()\n",
    "# 0.9689 20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9380003861799541"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC(n_estimators=10, random_state=0),x,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.27 s ± 96 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cross_val_score(RFC(n_estimators=10, random_state=0),x,y,cv=5).mean()\n",
    "# 0.9388 11.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388098166696807"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC(n_estimators=10, random_state=0),x_fsvar,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385004515100317"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC(n_estimators=10, random_state=0), x_var0,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.29 s ± 321 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cross_val_score(RFC(n_estimators=10, random_state=0),x_fsvar,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为什么RF>>KNN?且方差过滤对随机森林没有很大影响？\n",
    "\n",
    "这是因为原理不同。KNN，单棵决策树、SVM、神经网络，回归算法，都需要遍历特征或升维来进行运算，本身运算量大，所以方差对他们来说很重要。但对于不需要遍历特征的算法，如随机森林随机选择特征进行分枝，本身运算速度快。且无论过滤法如何减少特征，随机森林都只会选取固定的数量的特征来建模，故方差过滤对其影响不大。\n",
    "> 过滤法的主要对象：需要遍历特征或升维的算法。\n",
    "> 过滤法的主要目的：在保证算法的表现下，减少特征数量来减少计算成本。\n",
    "\n",
    "- 为什么说方差过滤常常用作数据预处理？\n",
    "方差过滤：不一定保证模型表现会变好。当threshold较大时，可能会滤除有效特征。\n",
    "\n",
    "怎么选择方差阈值：阈值为0或者较小，来消除一些明显用不到的特征。然后采取其他的特征选择方法来进一步进行特征工程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方过滤\n",
    "针对离散型标签（即分类问题的相关性过滤），非负特征和标签之间的卡方统计量，并按照卡方统计量由高到低为特征排名。再用SelectKBest来选取前K个特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X_fschi = SelectKBest(chi2, k=300).fit_transform(x_fsvar,y)\n",
    "X_fschi.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333098667649198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机森林分类\n",
    "cross_val_score(RFC(n_estimators=10, random_state=0), X_fschi,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与x_fsvar相比较而言0.9388，效果降低，说明过滤了有效特征\n",
    "- 怎样选取K：学习曲线（时间长）-> P值选择k\n",
    "显著性水平p<0.05/0.01->数据相关，从chi2实例化的模型中的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chivalue, pvalues_chi = chi2(x_fsvar,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chivalue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.37556612e-202, 0.00000000e+000, 0.00000000e+000, 8.14984992e-014,\n",
       "       4.82170664e-027, 1.08842996e-102, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       2.39754926e-120, 4.63737072e-052, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 2.91066191e-304,\n",
       "       3.65562117e-249, 1.41443562e-112, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       1.15881803e-232, 1.98924448e-065, 1.01652104e-093, 3.94593756e-137,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 2.39380167e-202,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       2.83241906e-034, 6.97450482e-005, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 6.54874128e-099,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 5.86540326e-208, 3.13821928e-294,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 1.58055668e-187, 9.05682514e-050,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 4.41444732e-152, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       7.30286234e-064, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 2.17301441e-087,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 9.60006195e-088, 1.16460365e-144,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       2.59192370e-185, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.09702410e-102,\n",
       "       9.05682514e-050, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.63318083e-071,\n",
       "       4.35564082e-048, 8.29908028e-010, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 2.94468006e-136,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       2.16329150e-268, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 8.09244964e-154, 2.13607370e-078, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 2.14884679e-187, 6.30069567e-197, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 6.07648663e-053,\n",
       "       7.79051208e-103, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 6.35966148e-215])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k值怎么取，消除p值大于显著性水平的特征\n",
    "k = chivalue.shape[0] - (pvalues_chi>0.05).sum()\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过方差过滤后的特征经卡方检验均为有效特征，不需要过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F检验\n",
    "ANOVA，既可以回归也可分类，用来捕捉每个特征于标签之间的线性关系的过滤方法。\n",
    "数据服从正太分布效果时效果稳定，预处理.\n",
    "- SelectKBest\n",
    "- 原假设：数据不存在显著的线性关系。<0.05，相关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "F, pvaluse_f = f_classif(x_fsvar,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不线性相关的特征个数\n",
    "(pvaluse_f>0.01).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过方差过滤后的特征经F检验均为线性有关，不需要过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 互信息法\n",
    "既可以回归也可分类，用来捕捉每个特征于标签之间的**任意关系**（包括西南行和非线性）的过滤方法。比F检验更加强大\n",
    "- 不返回p值或F值类似的统计量，返回每个特征与目标之间的互信息量的估计，返回[0,1]（[独立,完全相关]）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "\n",
    "result = MIC(x_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fsmic = SelectKBest(MIC,k=300).fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fsmic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398328527673006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC(n_estimators=10, random_state=0),x_fsmic,y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 包裹式\n",
    "包裹式特征选择直接把最终要使用的学习器性能作为特征子集的评价标准。para:estimator:带coef_,feature_importances_属性或者l1/l2惩罚项**实例化之后才能运行**\n",
    "threshold: 特征重要性阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "RFC_ = RFC(n_estimators=10,random_state=0)\n",
    "X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 47)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.005是比较高的阈值，按重要性分每个特征1/782约为0.001\n",
    "# 此处筛出了较多特征\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 怎么选取threshold\n",
    "# 学习曲线， 只有学习曲线？\n",
    "RFC_.fit(x,y).feature_importances_\n",
    "threshold = np.linspace(0,(RFC_.fit(x,y).feature_importances_).max(),20)# 必须传入实例化的评估器\n",
    "threshold = np.linspace(0,0.001,20) # 进一步细化\n",
    "score = []\n",
    "\n",
    "for th in threshold:\n",
    "    RFEX_embedded = SelectFromModel(RFC_, th).fit_transform(X,y)\n",
    "    s = cross_val_score(RFC_, X_embedded,y,cv=5).mean()\n",
    "    score.append(s)\n",
    "    \n",
    "plt.plot(threshold, score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = SelectFromModel(RFC_, 0.001).fit_transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 279)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9351434640469405"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC_, X_embedded,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌入法\n",
    "较小的特征数量，有效的组合，高效。\n",
    "\n",
    "嵌入式特征选择将特征选择过程与学习器训练过程融为一体，两者在同一优化过程中完成,黑河中的算法不是目标算法（RF）,而是数据挖掘算法，每一次递归的使用修剪后的特征，而不是所有特征。\n",
    "\n",
    "class sklearn.feature_selection.RFE(estimator,n_feature_to_select=None,step=1)\n",
    "\n",
    "n_feature_to_select: 要选择特征的个数\n",
    "\n",
    "step:每次递归删除的特征\n",
    "- RFE类的两个重要属性：.support_:返回所有特征最后是否被选中的特征矩阵\n",
    "                    \n",
    "                    .ranking返回特征的按数次迭代中综合重要性的排名，在前面越重要\n",
    "- RFEcv，增加参数cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "RFC_ = RFC(n_estimators=100,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(RFC_,n_features_to_select=340, step=50).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wrapper = selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637148832441458"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC_,X_wrapper,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion\n",
    "\n",
    "当**数据量很大**的时候，优先使用方差过滤和互信息法调整，再加上其他特征选择方法。使用**逻辑回归**时，优先使用Embedded。使用**SVM**，优先采用包装法。迷茫时，从过滤法开始，具体数据具体分析。\n",
    "\n",
    "特征选择只是特征工程中的第一步，特征创造或者特征提取来寻找高级特征。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
